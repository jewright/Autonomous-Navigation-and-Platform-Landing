# Autonomous Navigation using a Jackal UGV
## Overview


### Hardware Used



## Vicon 
Vicon, a motion capture system, was utilized in the beggining of this project to learn position and localization. The Vicon specified environment was used to obtain the location of the Jackal UGV and a UAV.  


### Camera Calibration 
To begin the usage of Vicon, the cameras must be calibrated. A wand provided for the system has flashing red LEDs and you must walk around and wave it until the cameras no longer blink. 
![IMG_8652](https://user-images.githubusercontent.com/98404383/180495459-b36c5bf2-4d38-4bd5-bdef-b6bb3eecb491.jpeg)


### Object Identification and Interaction. 
The interaction between the Vicon system, Jackal UGV, and UAV 

### Scripts



## Jackal UGV

### Hardware

### Installing ROS and Jackal Packages on Host PC

### Simulation using Gazebo and RViz

### Reinstall Jackal UGV ISO

### Network Configuration of the Jackal and Host PC

### Controlling Jackal 

### Bumblebee2 (Stereo Vision Camera)

### Hokuyo UST-10LX (2D LiDAR sensor) 
















To advance autonomous navigation and landing, I utilzed robotic software (ROS)

## Vicon Motion Capture System
Vicon, which is a motion capture system, was utilized in the beginning to learn the position and location of the UGV in a specified environment within the lab. The Vicon system required camera calibration and object identification to work alongside the Jackal UGV. For interaction between the two, Wi-Fi is used for Vicon to launch through the onboard computer within the Jackal UGV. This interaction allows the data from the Jackal UGV to be obtained and recorded. For behavioral control of the UGV, Python, and ROS are used for programming implementations. I wrote many scripts for directional movements and routes, such as a linear and square. I created a personalized map of the lab environment used for this project. 

The Jackal UGV was used as the platform landing for the UAV. 












<p align="center">

</p>
